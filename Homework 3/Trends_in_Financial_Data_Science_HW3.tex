\documentclass[11pt]{article}

\usepackage{amsmath,amsthm,amssymb}

%%%%% Matrix stretcher
% use it as:
%\begin{pmatrix}[1.5]
% ...
\makeatletter
\renewcommand*\env@matrix[1][\arraystretch]{%
  \edef\arraystretch{#1}%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols c}}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\extrafootertext[1]{%
    \bgroup
    \renewcommand\thefootnote{\fnsymbol{footnote}}%
    \renewcommand\thempfootnote{\fnsymbol{mpfootnote}}%
    \footnotetext[0]{#1}%
    \egroup
}


%%%%%%%%%%%%% Colors %%%%%%%%%%%%%
\usepackage[dvipsnames]{xcolor}

\definecolor{C0}{HTML}{1d1d1d}
\definecolor{C1}{HTML}{1e3668}
\definecolor{C2}{HTML}{199d8b}
\definecolor{C3}{HTML}{d52f4c}
\definecolor{C4}{HTML}{5ab2d6}
\definecolor{C5}{HTML}{ffb268}
\definecolor{C6}{HTML}{ff7300} % for commenting - {fire orange}dd571c
\definecolor{C7}{HTML}{777b7e} % for remarks - {steel grey}
\color{C0}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%% Fonts %%%%%%%%%%%%% 
%\usepackage{fontspec}
\usepackage[no-math]{fontspec} % for text

\emergencystretch=8pt
\hyphenpenalty=1000 % default 50
\tolerance=800      % default 200
%\righthyphenmin=4
%\lefthyphenmin=4

%%% Text Font: Vollkorn + Math Font: Latin Modern (default) %%%
\setmainfont{Vollkorn}[
UprightFont = Vollkorn-Regular,
ItalicFont =Vollkorn-Italic, 
BoldItalicFont={Vollkorn-BoldItalic},
BoldFont = Vollkorn-Bold,
RawFeature=+lnum,
WordSpace=1.7,
] 

%%% We need this for math font packages other than latin modern %%%
% \usepackage{unicode-math}        % for math

%%% Text Font: Palatino + Math Font: Asana-Math %%%
%\setmainfont{Palatino}[
%BoldFont = Palatino-Bold,
%ItalicFont = Palatino-Italic,
%BoldItalicFont={Palatino-BoldItalic},
%RawFeature=+lnum,
%WordSpace=1.7,
%]
%\setmathfont{asana-math}

%%% Text Font: Arno Pro + Math Font: Minion Pro %%%
%\setmainfont{Arno Pro}[
%UprightFont = *-Regular,
%ItalicFont = Vollkorn-Italic, 
%BoldItalicFont={*-BoldItalic},
%BoldFont = *-Bold,
%RawFeature=+lnum,
%WordSpace=1.7,
%Scale= 1.1
%] 
% Minion Pro is too expensive

%%% Math Fonts %%%
%\setmathfont{Vollkorn}
%\setmathfont{Latin Modern Math}
%\setmathfont{TeX Gyre Pagella Math}
%\setmathfont{TeX Gyre Termes Math}
%\setmathfont{TeX Gyre DejaVu Math}
%\setmathfont[Scale=MatchLowercase]{DejaVu Math TeX Gyre}
%\setmathfont{XITS Math}
%\setmathfont{Libertinus Math}
%\setmathfont[Scale=MatchUppercase]{Asana Math}
%\setmathfont{STIX Two Math}

%\usepackage{kpfonts-otf}
%\setmathfont{KpMath-Regular.otf}[version=regular]
%\setmathfont{KpMath-Bold.otf}[version=bold]
%\setmathfont{KpMath-Semibold.otf}[version=semibold]
%\setmathfont{KpMath-Sans.otf}[version=sans]
%\setmathfont{KpMath-Light.otf}[version=light]


%%% CJK Fonts %%%
\usepackage[scale=.78]{luatexja-fontspec}
\setmainjfont{BabelStone Han}[AutoFakeBold]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% This package simplifies the insertion of external multi-page PDF or PS documents.
\usepackage{pdfpages}

% cref
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=C4,
    filecolor=magenta,      
    urlcolor=cyan,
    }

\usepackage[nameinlink,noabbrev,capitalize]{cleveref}
% \crefname{ineq}{}{}
% \crefname{equation}{}{}
% \creflabelformat{ineq}{#2{\textup{(1)}}#3}
% \creflabelformat{equation}{#2\textup{(#1)}#3}

%%%%%%%%%%%%% Environments %%%%%%%%%%%%%%%%
%amsthm has three separate predefined styles:	
%
%\theoremstyle{plain} is the default. it sets the text in italic and adds extra space above and below the \newtheorems listed below it in the input. it is recommended for theorems, corollaries, lemmas, propositions, conjectures, criteria, and (possibly; depends on the subject area) algorithms.
%
%\theoremstyle{definition} adds extra space above and below, but sets the text in roman. it is recommended for definitions, conditions, problems, and examples; i've alse seen it used for exercises.
%
%\theoremstyle{remark} is set in roman, with no additional space above or below. it is recommended for remarks, notes, notation, claims, summaries, acknowledgments, cases, and conclusions.

%%%  theorem-like environment %%%
\theoremstyle{plain} % default theorem style
\newtheorem{theorem}{Theorem}[section]
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}

\newtheorem{definition}[theorem]{Definition}

%%% definition-like environment %%%
%\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{problem}[theorem]{Problem}


%%% framed package is great %%%
\usepackage{framed}
\newenvironment{solution}
{\color{C2}\normalfont\begin{framed}\begingroup\textbf{Solution:} }
  {\endgroup\end{framed}}

\newenvironment{topic}
{\color{C2}\normalfont\begin{framed}\begingroup }
  {\endgroup\end{framed}}

\newtheoremstyle{remark}% name of the style to be used
  {}% measure of space to leave above the theorem. E.g.: 3pt
  {}% measure of space to leave below the theorem. E.g.: 3pt
  {\color{C3}}% name of font to use in the body of the theorem
  {}% measure of space to indent
  {\color{C3}\bfseries}% name of head font
  {.}% punctuation between head and body
  { }% space after theorem head; " " = normal interword space
  {}
\theoremstyle{remark}
\newtheorem{remarkx}[theorem]{Remark}
\newenvironment{remark}
  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\triangle$}\remarkx}
  {\popQED\endremarkx}
  
\newenvironment{point}
  {\O~~}
  {}

\usepackage{thmtools}
\usepackage{thm-restate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% This package is for the long equal sign \xlongequal{}
\usepackage{extarrows}

%%%%%%%%%%%% Algorithms %%%%%%%%%%%%
\usepackage{etoolbox} 
\usepackage{setspace}
\usepackage{algorithm}
\AtBeginEnvironment{algorithmic}{\onehalfspacing}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}

\algrenewcommand\algorithmicindent{1.0em}
\let\Algorithm\algorithm
\renewcommand\algorithm[1][]{\Algorithm[#1]}%\fontsize{11}{16}\selectfont}

\newenvironment{labelalgorithm}[4][t]{%
\begin{algorithm}[#1]
%\newcommand{\thealgorithmlabel}{#2}
\newcommand{\thealgorithmname}{#3}
%\newcommand{\thealgorithmcap}{#4}
\customlabel{alg:name:#2}{\textproc{#3}}
%\customlabel{alg:cap:#2}{#4}
\caption{#4}\label{alg:#2}
}{\end{algorithm}}


\makeatletter
\newcommand{\customlabel}[2]{%
   \protected@write \@auxout {}{\string \newlabel {#1}{{#2}{\thepage}{#2}{#1}{}} }%
   \hypertarget{#1}{}%
}
\makeatother


%\algdef{SE}[FUNCTION]{Procedure}{EndProcedure}%
%   [2]{\algorithmicclass\ \textproc{#1}\ifthenelse{\equal{#2}{}}{}{$($#2$)$}}%
%   {\algorithmicend\ \algorithmicclass}%

\algnewcommand\algorithmicclass{\textbf{class}}
\algdef{SE}[FUNCTION]{Class}{EndClass}%
   [2]{\algorithmicclass\ \textproc{#1}\ifthenelse{\equal{#2}{}}{}{$($#2$)$}}%
   {\algorithmicend\ \algorithmicclass}%

% Tells algorithmicx not to print an empty line if `noend' is set 
\makeatletter
\ifthenelse{\equal{\ALG@noend}{t}}%
  {\algtext*{EndClass}}
  {}%
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Page Formatting
\usepackage[
    paper=a3paper,
    inner=22mm,         % Inner margin
    outer=22mm,         % Outer margin
    bindingoffset=0mm, % Binding offset
    top=28mm,           % Top margin
    bottom=22mm,        % Bottom margin
    %showframe,         % show how the type block is set on the page
]{geometry}

\setlength{\parindent}{0em}
\setlength{\parskip}{.7em}


\usepackage{tikz}
\usepackage{graphicx}
\usepackage{enumitem}
\setlist{topsep=0pt}

\usepackage{bm}

\usepackage[font=scriptsize,labelfont=bf]{caption}
\usepackage{listings}
\lstset{basicstyle=\ttfamily,breaklines=true}
% \setlength{\parskip}{1em}
% \setlength{\parindent}{0em}
\usepackage{dsfont}
\newcommand{\bOne}{\mathds{1}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\VV}{\mathbb{V}}
\newcommand{\CoV}{\operatorname{Co\mathbb{V}}}

% header
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[L]{\small   \bfseries Homework}
\fancyhead[C]{\small   \bfseries Fall 2023}
\fancyhead[R]{\small   \bfseries Zhou}


\begin{document}

\begin{center}
  \text{\Large{ICA, Gaussian Process, Fama-French 5 factor
      model, HMMs and jump models
    }}

  {\text{Kaiwen Zhou}}
\end{center}
\vspace{2em}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Topic: Random Feature Maps}

Given a set of functions of a single variable
\(\left\{\phi_{i}(t)\right\}_{i=1}^{N}\) and discrete observations
\(\left(t_{j}\right)_{j=1}^{M}\) one can form both the \(N \times M\) design
matrix \(\boldsymbol{\Phi}=\left[\Phi_{j
i}\right]:=\left[\phi_{i}\left(t_{j}\right)\right]\) and the \(N \times N\)
kernel \(\mathbf{K}=\left[K\left(t_{j}, t_{l}\right)\right]:=\boldsymbol{\Phi} \boldsymbol{\Phi}^\top\). As
we will see in later lectures, often \(M \gg N\) and in fact in most cases
\(M=\infty\). In this exercise we will consider random feature map functions.

\begin{enumerate}
  \item[(a)] Suppose \(\phi_{i}\left(t_{j}\right)\) are simply white noise
  vectors, e.g. each entry in the design matrix is an i.i.d. realization of
  random mean zero Gaussian with variance 1. In this case one can think of each
  feature map \(\phi_{\mathbf{w}}\left(t_{j}\right)\equiv \mathbf{w}\)
  as a random constant vector function taking a value \(\mathbf{w}\). Because
  one is drawing \(M\) such random vectors, the feature maps are \(M\) random
  vector-valued constant functions. Construct the kernel matrix and find its
  eigenvectors and eigenvalues. For fixed \(N=100\), plot the histogram of the
  eigenvalues of \(\mathbf{K}\) as a function of \(q=M / N\) for
  \(M=10,100,1000\). Plot the top 3 eigenvectors in each case.
  \item[(b)] Repeat (a), but this time assume \(\phi_{i}\left(t_{j}\right)\) is
  a random draw of discretized Brownian motion paths evaluated at \(t_{j}=(j /
  N)_{j=0}^{N} \in[0,1)\). Each feature map is therefore the cumulative sum of
  Brownian increments, where the Gaussian has zero mean and a variance of \(1 /
  N\). Do you see any structure in the top three eigenvectors of the kernel
  matrix resulting from this Brownian motion design matrix? Empirically, how
  fast does the spectrum of the \(n\)-th eigenvalue decay as a function of \(n\)
  for each of the values of \(q\) in (a)?
  \item[(c)] Investigate the stability of your results in (a) and (b) to
  resampling of your random feature maps. Which aspects appear stable and which
  aspects do not? Explain your findings.
\end{enumerate}

\begin{solution}

\end{solution}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Topic: Brownian Motion and Brownian Bridge Gaussian Processes (GPs)}

In class we suggested that both the Brownian motion
\begin{align}
  y_{t}=\int_{0}^{t} d W_{t} \label{eq:brownian motion}
\end{align}


and the Brownian bridge stochastic process
\begin{align}
y_{t}=\int_{0}^{t} d W_{t}, \quad \text{where} \ t \leq 1 \text{ and } y(1)=0
\label{eq:brownian bridge}
\end{align}

can be thought of as GPs.

\begin{enumerate}
    \item[(a)] Prove that the kernel of \cref{eq:brownian motion} is \( K_{\mathrm{BM}}\left(t,
    t^{\prime}\right)=\min \left(t, t^{\prime}\right) \) and that the kernel of
    \cref{eq:brownian bridge} is \( K_{\mathrm{BB}}\left(t, t^{\prime}\right)=\min \left(t,
    t^{\prime}\right)-t t^{\prime} \).
    
    \item[(b)] Implement the kernels \cref{eq:brownian motion} and \cref{eq:brownian bridge} in Scikit-Learn (e.g. see the
    kernels they currently have implemented and inherit from the kernel class)
    and show that paths generated using \cref{eq:brownian motion} have properties of Brownian motion
    paths, while those generated using \cref{eq:brownian bridge} have properties of a Brownian bridge.
    Plot 100 paths generated from the priors of each model.
    
    \item[(c)] Brownian bridge can be thought of as Brownian motion conditioned
    to pass through \( y(1)=0 \). Within the GP framework, one should therefore
    be able to simulate Brownian bridge paths using the posterior density
    corresponding to the kernel (1), conditioned on a single training point \(
    (t, y)=(1,0) \). Using the GP formula for the posterior density as a
    function of the kernel in \cref{eq:brownian motion}, show that for a single training point \( (t,
    y)=(1,0) \), it corresponds to sampling from the distribution \(
    \mathcal{N}\left(0, K_{\mathrm{BB}}\left(t, t^{\prime}\right)\right) \).
    Plot 100 paths of the posterior density of Brownian Motion trained on \( (t,
    y)=(1,0) \).
\end{enumerate}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Topic: Applying HMMs and Jump Models to Equity Factors}

The deliverables for this homework are: 
\begin{enumerate}
  \item one Python notebook (that will read in all the data needed and then does
  all necessary calculations),
  \item all data files you use. Make sure to comment and annotate your steps in
  the notebook clearly.
\end{enumerate}

\href{https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip}{Download}
the daily Fama-French 5-factor model (FF5M). A description of the factors is
\href{https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/f-f_5_factors_2x3.html}{available
here}. You will be using Mkt-RF, SMB, HML, RMW, and CMA for the time period
2010/01/04 through 2023/09/29.

Create one notebook with all your code, analysis, and answers to the following
questions:

\begin{enumerate}
  \item[(a)] Briefly describe how the 5 time series from FF5M have been
  constructed.
  
  \item[(b)] Produce a table of average return, volatility, and correlations of
  the FF5M time series. Returns and volatilities should be annualized.
  
  \item[(c)] Compute and plot cumulative daily returns and volatilities for the
  5 time series as in the top half of Exhibit 10 in "Greedy Online
  Classification of Persistent Market States Using Realized Intraday Volatility
  Features" by Nystrup, Kolm, and Lindström covered in one of the lectures. The
  result for Mkt-RF will be similar to the S\&P500 used in the exhibit.
  
  \item[(d)] For each time series, compare the hidden states inferred from
  hmmlearn (fits an HMM) and the jump model. For the purposes of this analysis,
  you can assume there are two hidden states. While the results from hmmlearn
  only depend on the initialization, the results for the jump model depend on
  your initialization and the penalty parameter, \(\lambda\). Therefore, for the
  jump model, you will need to experiment with different values for \(\lambda\).
  To address the issue that the results depend on the initialization, for each
  model do the inference with 5 different initializations and pick the
  initialization that gives the best result.
  
  \item[(e)] For each of the 5 factors of the FF5M, write out your findings. In
  particular: 
  \begin{itemize}
    \item For each factor, how do the state sequences from the HMM and jump
    model compare?
    \item How do the state sequences compare across factors? (Hint: Develop a
    way to plot/visualize the state sequences over time for easy comparison.)
  \end{itemize}
  
  \item[(f)] (Extra credit) Based on your results above, propose and test a
  trading strategy for each of the factors. Daily, each strategy should decide
  whether to go long one unit of the factor or not to hold it (i.e., hold zero
  units of the factor).
\end{enumerate}

Important:

\begin{itemize}
  \item Make sure each strategy is deployed out-of-sample. In other words, you
  can only use information available to you before the day you make each trade
  decision.
  \item For each factor, use the long-only strategy as a benchmark. Compare the
  performance of your trading strategy in each of the factors with the long-only
  strategy in the factor. Does your strategy outperform? Compute its annualized
  average return, annualized volatility, annualized Sharpe ratio, and annualized
  \(\alpha\) and \(\beta\) relative to the benchmark strategy.
\end{itemize}



























\end{document}

